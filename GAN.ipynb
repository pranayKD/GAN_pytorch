{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "exKDZTdL9N4M"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-tGkIhxumZv"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "latent = 100\n",
        "img_size = 28\n",
        "\n",
        "# discriminator \n",
        "disc_hidden = [img_size*img_size, 1000, 500, 200]\n",
        "\n",
        "# generator\n",
        "gen_hidden = [latent, 200, 500, 1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLgPm7tn9ck0"
      },
      "source": [
        "train_set = datasets.MNIST(root='../mnist_data', train=True,  download=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Hz8yLW9vyI"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5),(0.5))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsG4l05G9yCP"
      },
      "source": [
        "class custom_mnist(Dataset):\n",
        "    def __init__(self, input_data):\n",
        "        super().__init__()\n",
        "        self.data = input_data\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return transform(self.data[idx][0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0sHC-zmC7NZ"
      },
      "source": [
        "mnist_train = custom_mnist(train_set)\n",
        "plt.imshow(mnist_train[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPJXP_ar-B6M"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, hidden):\n",
        "        super().__init__()\n",
        "        self.h1 = hidden\n",
        "        self.h2 = hidden[1:] + [1]\n",
        "\n",
        "        self.net = []\n",
        "\n",
        "        for l1, l2 in zip(self.h1, self.h2):\n",
        "            self.net.append(nn.Linear(l1,l2))\n",
        "            self.net.append(nn.LeakyReLU(0.2))\n",
        "            self.net.append(nn.Dropout(p=0.5))\n",
        "\n",
        "        self.net = self.net[:-2]\n",
        "        self.net = nn.ModuleList(self.net)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = torch.reshape(x, (-1,img_size*img_size))\n",
        "        out = nn.Sequential(*self.net)(x)\n",
        "        return torch.sigmoid(out)\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, hidden):\n",
        "        super().__init__()\n",
        "        self.h1 = hidden\n",
        "        self.h2 = hidden[1:] + [img_size*img_size]\n",
        "\n",
        "        self.net = []\n",
        "\n",
        "        for l1, l2 in zip(self.h1, self.h2):\n",
        "            self.net.append(nn.Linear(l1,l2))\n",
        "            self.net.append(nn.LeakyReLU(0.2))\n",
        "\n",
        "        self.net = self.net[:-1]\n",
        "        self.net = nn.ModuleList(self.net)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = nn.Sequential(*self.net)(x)\n",
        "        out =  torch.tanh(out)\n",
        "        return torch.reshape(out, (-1,1,img_size,img_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQTcVG9I0f9r"
      },
      "source": [
        "## Very very important for sampling\n",
        "# torch.rand = samples from uniform dist\n",
        "# torch.randn = samples from normal dist - correct (use this one)\n",
        "\n",
        "\n",
        "def generate_fake_data(generator,num_data):\n",
        "    x = torch.randn(num_data, latent).to(device)\n",
        "    out = generator(x)\n",
        "    return out.to(device), torch.zeros(num_data,1).to(device)\n",
        "\n",
        "\n",
        "def generate_real_data(data):\n",
        "    return data.to(device), torch.ones(len(data),1).to(device)\n",
        "\n",
        "\n",
        "def display_generated_images(generator):\n",
        "    images,_ = generate_fake_data(generator, 16)\n",
        "    images = images.detach().to('cpu')\n",
        "    f, axarr = plt.subplots(4,4)\n",
        "\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            axarr[i,j].imshow(images[4*i+j][0])\n",
        "            axarr[i,j].axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPdX59yyFwQq"
      },
      "source": [
        "disc = Discriminator(disc_hidden).to(device)\n",
        "gen = Generator(gen_hidden).to(device)\n",
        "\n",
        "print(disc)\n",
        "print(gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxU4JzMP3fnO"
      },
      "source": [
        "\n",
        "disc_optim = Adam(disc.parameters(), lr = 0.0001)\n",
        "gen_optim = Adam(gen.parameters(), lr = 0.0001)\n",
        "\n",
        "criterion = nn.BCELoss().to(device)\n",
        "num_epochs = 40\n",
        "batch = 64 # take 64 from Pdata and 64 from Pgen\n",
        "\n",
        "disc_loss_hist = []\n",
        "gen_loss_hist = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loader = DataLoader(mnist_train, batch_size=batch, shuffle=True)\n",
        "\n",
        "\n",
        "    for idx,data in enumerate(train_loader):\n",
        "\n",
        "        ## Train discriminator\n",
        "\n",
        "        # create training data for discriminator\n",
        "        pdata,label_data = generate_real_data(data)\n",
        "        pgen, label_gen = generate_fake_data(gen, batch)\n",
        "\n",
        "        fin_data = torch.cat([pdata, pgen], dim=0)\n",
        "        fin_out = torch.cat([label_data, label_gen], dim=0)\n",
        "        # fin_out = torch.abs(fin_out - 0.1)\n",
        "\n",
        "        out = disc(fin_data)\n",
        "        d_loss = criterion(out,fin_out)\n",
        "\n",
        "\n",
        "        out = disc(pgen)\n",
        "        disc_optim.zero_grad()\n",
        "        d_loss.backward()\n",
        "        disc_optim.step()\n",
        "\n",
        "        disc_loss_hist.append(d_loss)\n",
        "\n",
        "        \n",
        "        ## Train generator\n",
        "\n",
        "        # For generator, for fooling the discriminator keep generated data points output as 1\n",
        "        pgen, label_gen = generate_fake_data(gen, 2*batch)\n",
        "        label_gen = torch.ones(label_gen.shape).to(device)\n",
        "        out = disc(pgen)\n",
        "\n",
        "        g_loss = criterion(out,label_gen)\n",
        "        gen_optim.zero_grad()\n",
        "        g_loss.backward()\n",
        "        gen_optim.step()\n",
        "\n",
        "\n",
        "        gen_loss_hist.append(g_loss)\n",
        "\n",
        "\n",
        "    print(epoch)\n",
        "    display_generated_images(gen)\n",
        "    plt.plot(disc_loss_hist, label='disc')\n",
        "    plt.plot(gen_loss_hist, label='gen')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOEKqhBZ_GNW"
      },
      "source": [
        "a = torch.randn(1,latent).to(device)\n",
        "b = torch.randn(2,latent).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VkNYwbvxz9v"
      },
      "source": [
        "plt.imshow(gen(a)[0][0].detach().to('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHJ9Wjutx491"
      },
      "source": [
        "plt.imshow(gen(b)[0][0].detach().to('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLdqj1hbyIsa"
      },
      "source": [
        "len = 10\n",
        "\n",
        "f, axarr = plt.subplots(1,len)\n",
        "for idx,i in enumerate(np.linspace(0,1,len)):\n",
        "    \n",
        "    vec = i * a + (1-i)*b\n",
        "    axarr[idx].imshow(gen(vec)[0][0].detach().to('cpu'))\n",
        "    axarr[idx].axis('off')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV37eR3K8JTH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}